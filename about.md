---
layout: article
title: About
permalink: /about/
---

> Knowing WHAT is not enough, I need to know WHY.


## 个人信息
* 王冲/男/1991年
* 本科/西安邮电大学
* 专业/通信工程
* 工作年限：4年
* 技术博客: http://www.chongblog.xyz
* Github:  https://github.com/wangchong386
* 期望职位：数据仓库工程师/大数据开发
* 期望薪资：面议


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
## 自我评价
勤奋，踏实，对工作充满热情, 对数据敏感，有较强的逻辑分析能力，有互联网数据仓库开发经验；
自学能力与环境适应能力较强，善于分析解决问题，并提出可行性方案；
良好的心理素质，具备良好的编码习惯，能够承受高强度的工作压力,具有良好的团队合作精神。
## 工作经历
#####  百度（2017年8月至今）
* 职位：高级研发工程师
* 百度大搜-oppd-ubs数据平台
* 主要职责：
  * 负责ubs数据平台ETL任务的开发与运维工作。参与流量的反作弊策略以及回溯等运维工作，保证自身原因0错误，保障核心数据流的SLA
  * 负责开发手机百度kpi&多维分析模型任务
  * 手机百度首页统计开发任务

#####  敦煌网（2014年9月2017年8月）
* 职位：数据开发工程师
* 部门：大数据/基础架构
* 主要职责：
  * 负责公司hadoop集群搭建以及优化。将公司hadoop集群升级到2.0，增加kafka,spark,sparkstreaming等组件。为流式计算处理提供条件。对Yarn资源管理系统进行调优。
  * 参与数据开发,将Flume实时采集用户搜索曝光、点击、浏览、收藏等行为数据，使用kafka+sparkstreaming实时处理落到HDFS上，使用hsql/spark sql + shell 进行批处理开发。使用kettle进行调度依赖，将计算结果推送到关系数据库。
  * 负责ETL流程维护以及优化，支撑BI系统及数据挖掘所需数据需求，负责从数据源到数据集市整条链路的打通及故障处理维护工作 


## 项目经验
一. 数据智囊系统
* __项目时间__：2015年1月 - 2017-01月
* 项目描述：敦煌网为卖家量身打造的数据展示和分析工具，可帮卖家时实监控自身店铺经营指标数据；多维解析行业发展趋势；深入分析买家购买行为；时刻更新买家最新搜索习惯等。
* 集群规模： hadoop机器数45个
* 数据日吞吐量：2TB左右，日任务job数10000个，核心任务job数4000个
* 责任描述：
    * 将Flume实时采集用户行为数据，使用kafka+sparkstreaming实时处理落到HDFS上，经过ods基础层-->mds中间层-->sds应用层的ETL处理，将多维数据分析结果通过sqoop导入到Mysql中进行统一管理，ETL使用的hive sql/Pig计算+shell脚本来实现的。计算近7天，30，自然月的商户流量以及交易情况，并且计算同环比指标。对整个ETL流程优化，保证数据实时准确完成处理。

## 职业技能
* 掌握hadoop集群的搭建以及各组件的维护升级，熟悉Yarn资源管理以及调度配置。
* 了解数据仓库建设基本思路，有数据仓库建设项目经验，熟悉数据仓库的主题分析.构建DMP大数据平台经验
* 语言：熟悉shell，python。能够快速理解JAVA代码，熟悉IDEA等开发环境
* 熟悉 spark内存分布式计算(Spark core,Spark sql,Spark streaming等组件)
* 熟悉Flume日志获取，Kafka消息中间件，sqoop数据传输,Zeppelin交互式分析查询
* 精通spark-sql或hive sql，编写UDF,有较强的开发调优能力
* 熟悉oracle,mysql,postgresql等主流数据库
* 熟练ETL设计与开发，熟悉Oozie,kettle,Rundeck等ETL调度依赖工具
* 熟悉使用Smartbi、BO、Saiku报表工具,及集成到项目
* 熟练使用Git,svn等版本工具进行合作开发
