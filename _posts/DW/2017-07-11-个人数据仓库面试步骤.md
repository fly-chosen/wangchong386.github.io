---
layout: article
title:  "数据仓库面试步骤"
categories: DW
toc: true
image:
    teaser: /teaser/面试工作-25265315.jpg
---

> 本文主要介绍自己对于目前面试准备，面试官可能会问到的一些问题，基于个人对这部分进行梳理和总结

## 概述
俗话说：知己知彼，方能百战百胜。所以准备换工作之前，如果觉得自己不是业界的大牛级别的人物，或者好长时间没有参加过面试。我觉得还是很有必要模拟一下面试，让自己的优势发挥出来，让面试官跟着自己的节奏走。而不是让面试官想方设法的引导你，最后会将自己逼到死胡同，将自己不太擅长的方面暴露出来，影响后续的面试环节的发挥。

## 介绍
> 这个回合非常重要，如果介绍的非常好，不仅可以为后面面试官提问做伏笔，还可以让面试官对你有好感。所以建议准备一个十分钟时长的介绍。(其实也是为了暖场，避免气氛过于尴尬)

* 自我介绍（也就是基础介绍）
  我叫**，来自陕西咸阳。西安邮电大学本科毕业。毕业之后就来到北京，在亚信公司做了一年的ETL工程师。后来15年9月想在互联网公司有所发展，来到现在的公司敦煌网。目前再大数据/基础架构部门担任数据开发工程师。
* 技术介绍以及项目介绍
* 技术亮点以及个人兴趣爱好介绍

## 正式技术和项目面试开始
### 项目面试

(1). __介绍目前集群的情况__：（主要是介绍下公司目前的规模以及使用的技术组件）

&emsp;&emsp;目前负责约100台服务器：Dell PowerEdge R730xd。32Core 64G内存，2TB/3TB X 6 300GB X 1

|名称  |规模 |
集群管理系统|CDH5.9.0
已使用的组件|HDFS、YARN、Flume、Spark、Oozie、Sqoop、Kafka、Hive、Hue、Zookeeper、Impala、Pig
hadoop机器数|45个
总数据量|420TB
数据日增量|2T
日任务job数|10000个
核心任务job数|4000个

(2) 项目大体介绍：
(3) 个人负责的任务：
(4) hive：
* Hive是基于Hadoop的一个数据仓库系统，在各大公司都有广泛的应用。公司数据仓库是基于Hive搭建，每天执行近万次的Hive ETL计算流程，负责每天数百GB的数据存储和分析。Hive的稳定性和性能对我们的数据分析非常关键。 

* hive的编译过程大体说下：
   * 词法分析/语法分析
       * 首先，客户端接受到请求者的sql命令，Antlr实现对sql进行词法和语法解析。将sql转化为抽象数
   * 语义分析：
       * 从Megastore获取模式信息，验证SQL语句中队表名，列名，以及数据类型的检查和隐式转换
   * 逻辑计划生成
       * 生成逻辑计划--算子树
   * 逻辑计划优化
       * 对算字数进行优化，包括列剪枝，分区剪枝，谓词下推等
   * 物理计划生成
       * 将逻辑计划生成包含由MapReduce任务组成的DAG的物理计划
   * 物理计划执行
       * 将DAG发送到Hadoop集群进行执行 
 
(5). __优化__:

* 离线计算处理：将Flume采集过来的snappy文件直接落到HDFS上，通过pig脚本解析到表，经过ods基础层-->mds中间层-->sds应用层的ETL处理，然后通过sqoop/sqlloader推送到RDBMS关系数据库中。ETL使用的hive sql/Pig计算+shell脚本来实现的。这种方式是很稳定的，就是处理时间比较长，存在效率问题。但是随着业务发展，当数据量比较大的时候，流程的运行时间较长，这些ETL流程通常处于比较上游的位置，会直接影响到一系列下游的完成时间以及各种重要数据报表的生成。更重要的是还给很多提供给卖家收费产品以及广告收费扣费产品的计算支持。
  * ETL流程优化：
     * 公司ETL处理使用的调度工具是：Crontab/rundeck
     * 使用kettle来维护ETL job依赖关系。这个开源工具相对于Oozie这种调度流程工具更界面化，易于配置管理
     * 通过对每天处理日志log进行分析，将每个任务处理时间打印出来。将依赖关系表进行调整。将表之间没有依赖关系的并行处理。充分利用集群资源。
  * hadoop集群优化
     * 升级hadoop2.0使用yarn进行资源调度，配置高可用ResourceManager HA高可用，保证集群稳定。
  * hive sql性能调优
     * 通过对源码分析。 
  * 使用spark引擎计算处理
     * 由于公司数据处理以Hive SQL为主，底层计算使用mapreduce引擎。部分相对复杂的业务会由工程师编写MapReduce程序实现。随着业务的发展，单纯的Hive SQL查询或者MapReduce程序已经越来越难以满足数据处理和分析的需求。 所以觉得应该需要引入spark计算引擎，使用hive on spark进行处理分析。大大缩短整个流程时间。
   
### 技术基础面试

### 反问面试官
&emsp;&emsp;一般面试快结束时，面试官出于礼貌会问你有什么想问我的吗？
* 我们公式大数据平台的机器规模以及人员规模的情况？
* 这个岗位具体负责哪方面？

### HR面试
HR面试主要考察一个人的价值观，潜力和职业规划。所以进入这一关之前请想清楚几个问题：

* 
* 为什么离开目前的公司？
   * 希望自己有更好的发展 
* 你的职业规划是什么？
   * 还是想走技术这条路线，未来两三年内希望自己能在数据仓库开发方面能有所突破。
* 你平时喜欢逛的开源网站有哪些？
   * stackoverflow，oschina，spark技术社区 
* 遇到的瓶颈是什么？
* 你对加班的看法？
   * 如果是工作需要的话肯定会加班，比如像我现在的公司也会遇到加班，上线新产品或者故障处理等。但是同时我会提高个人工作效率，并将一些固化工作自动化解决。减少不必要的加班。
*  你期望薪酬是多少？
   * 会先问下，公司的年终奖和绩效是怎么样的？然后给说一个工资范围.再说下我现在的公司是16个月的季度奖和年终奖。   
* 如果是BAT的话，HR还会问是否了解他们公司的价值观？