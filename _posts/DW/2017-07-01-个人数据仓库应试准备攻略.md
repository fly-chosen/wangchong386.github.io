---
layout: article
title:  "数据仓库应试准备攻略"
categories: DW
toc: true
image:
    teaser: /teaser/工作面试-28956781.jpg
---

> 本文主要介绍自己对于目前面试准备，面试官可能会问到的一些问题，基于个人对这部分进行梳理和总结


## 概述
主要介绍个人对准备跳槽的一些准备，以及知识的梳理：
## 心态
* 保持良好积极的心态

&emsp;&emsp;其实找工作的阶段是心态转变的过程，因为实力摆在那块，短时间是很难提高了，所以心态是成功很重要的一个引子。比如说我个人第一份工作的时候，当时就是心里特别的担心面试官不要我，为什么还没有给offer.就这样诚惶诚恐的拿到第一个offer时候，心里突然感觉踏实多了，胆量也很大。没有以前那种和面试官拘谨的感觉了。反正至少不会失业。后面的也接着拿到几个互联网公司的offer了。
* 切莫失去信心

&emsp;&emsp; 一个好的面试过程通常是逐步推进的，面试官要通过不断深入的问题来判断被面试者的知识极限在哪里，所以没有必要担心被问到自己不知道答案的问题——那就是你的极限，然而那个极限或许已经可以满足这个职位了。在被推向极限时，最好能表现出积极思考的状态，有理有据的从一些基本原理出发去推论；此时漫无边际的胡乱回答一通或者畏缩而不回答都容易留下负面印象

## 实力
### Java知识
* 基础知识
 Java基础（面向对象、四个特性、重载重写、static和final等等很多东西）
* 首先介绍下JVM原理
  * JVM内存模型
  * GC垃圾回收，包括分代
  * GC算法
  * 收集器
  * 类加载和双亲委派
  * JVM调优
  * 内存泄漏和内存溢出
* GC 
  * 说明minor gc/full gc的触发条件、
  * OOM的触发条件
  * 降低GC的调优的策略
* IO/NIO相关
* 设计模式
  * 常用的
  * jdk中有的
* Web相关（servlet、cookie/session、Spring<AOP、IOC、MVC、事务、动态代理>
  * Mybatis
  * Tomcat
  * Hibernate等）
* 看jdk源码
### Linux知识
 内核
### 计算机网络
* OSI7层模型（TCP4层）
    * 每层的协议
    * url到页面的过程

### 数据仓库模型

* __三范式__:
  * 一范式：就是属性不可分割。属性是什么？就是表中的字段。
      * 特点：不可分割的意思按字面的理解就是最小单位，这个字段只能是一个值，不能被拆分成多个字段，否则就不符合第一范式了。当然能不能分割没有绝对的答案，还是需要看需求，跟着设计的目标而走。
      * 举例：比如学生信息表，姓名是不可拆分的的，作为一个字段。但是在国外，姓和名是需要分开的，有特别的意义，所以姓名这个字段是可拆分的。。所以能否拆分还是根据需求而定的，跟着设计的目标而走。
  * 二范式：就是要有主键，要求其他字段都依赖于主键。
      * 特点：为什么要有主键？没有主键就没有唯一性，没有唯一性在集合中就定位不到这行记录，所以要主键 。
  * 三范式：就是要消除传递依赖，方便理解，可以看做是“消除冗余”。
      * 特点：消除冗余应该比较好理解一些，就是各种信息只在一个地方存储，不出现在多张表中。
      
* __模型设计__:
  * 星型模型：当所有维表都直接连接到“ 事实表”上时，整个图解就像星星一样，故将该模型称为星型模型.星型架构是一种非正规化的结构，多维数据集的每一个维度都直接与事实表相连接，不存在渐变维度，所以数据有一定的冗余，如在地域维度表中，存在国家 A 省 B 的城市 C 以及国家 A 省 B 的城市 D 两条记录，那么国家 A 和省 B 的信息分别存储了两次，即存在冗余。 
  * 雪花模型：当有一个或多个维表没有直接连接到事实表上，而是通过其他维表连接到事实表上时，其图解就像多个雪花连接在一起，故称雪花模型。雪花模型是对星型模型的扩展。它对星型模型的维表进一步层次化，原有的各维表可能被扩展为小的事实表，形成一些局部的 " 层次 " 区域，这些被分解的表都连接到主维度表而不是事实表
  * 优缺点比较：星型模型因为数据的冗余所以很多统计查询不需要做外部的连接，因此一般情况下效率比雪花型模型要高。星型结构不用考虑很多正规化的因素，设计与实现都比较简单。雪花型模型由于去除了冗余，有些统计就需要通过表的联接才能产生，所以效率不一定有星型模型高。正规化也是一种比较复杂的过程，相应的数据库结构设计、数据的 ETL、以及后期的维护都要复杂一些。因此在冗余可以接受的前提下，实际运用中星型模型使用更多，也更有效率。雪花模型加载数据集市，因此ETL操作在设计上更加复杂，而且由于附属模型的限制，不能并行化。星形模型加载维度表，不需要再维度之间添加附属模型，因此ETL就相对简单，而且可以实现高度的并行化。
  
## hive sql
1. mapreduce的排序算法：
   [算法排序](http://www.uml.org.cn/bigdata/201607213.asp)

2. hive sql优化hive优化按照消耗I/O,消耗内存，消耗CPU进行优化的？

* (1)消耗I/O:
   * 1.执行引擎选择,Hive目前除了默认支持的Map-Reduce计算框架，还扩展了对Tez和Spark的支持，
  使得用户可以充分利用这两种计算框架的优势来提升查询性能。Tez和spark都不需要将中间结果写到HDFS上，
  而是直接写内存的，这样可以减少数据读取和写入磁盘到内存的时间。
   * 2.map输入，map输出，reduce输出等不进行压缩，会在落地到文件以及shuffle过程copy的时候，都会对I/O是极大的消耗
   * 3.文件没有压缩，文件格式使用rcfile这种列存储，进行优化。
   
* (2)消耗内存：
   * 1.count(distinct),引入了DISTINCT，因此在Map阶段无法利用combine对输出结果消重，必须将id作为Key输出，
  在Reduce阶段再对来自于不同Map Task、相同Key的结果进行消重，计入最终统计值。这唯一的Reduce Task需要Shuffle大量的数据，
  并且进行排序聚合等处理，这使得它成为整个作业的IO和运算瓶颈。
  可以先进行group by按照维度去重之后，将原来一个MapReduce作业转换为两个作业，在第一阶段选出全部的非重复id，
  在第二阶段再对这些已消重的id进行计数。这样在第一阶段我们可以通过增大Reduce的并发数，并发处理Map输出。
  在第二阶段，由于id已经消重，因此COUNT(*)操作在Map阶段不需要输出原id数据，
  只输出一个合并后的计数即可。这样即使第二阶段Hive强制指定一个Reduce Task，极少量的Map输出数据也不会使单一的Reduce Task成为瓶颈

  * 2.reduce过少。
  由于输入的数据特别大，做reduce处理的时候，分到reduce太少，会造成这几台机器内存消耗过大，可以调整reduce数，使得分到更多的reduce上
  进行执行，减轻负载
  * 3，排序的时候使用order by进行全局排序，会使得在一个reduce上进行实现。会使得单个reduce负载过高。Sort by 实现部分有序，
   单个reduce输出的结果是有序的，效率高，通常和DISTRIBUTE BY关键字一起使用（DISTRIBUTE BY关键字 可以指定map 到 reduce端的分发key）
   CLUSTER BY col1 等价于DISTRIBUTE BY col1 SORT BY col1.

* (3)消耗CPU:
   * 1. 小任务过多，初始化以及reduce阶段，会对CPU消耗，也会对I/o消耗。可以使用合并参数
   * 2. reduce过多，也会消耗更多的cpu
   * 3. 解压缩的时候会耗费CPU，但是HADOOP由于大部分计算是IO密集型而非CPU密集型，因此这种方法也会使用；

## 说说自己面试遇到的问题
一. 搜狐（高级bi工程师）：
广告部门

1. 离线计算的时候，每天抽取增量，然后又与昨天的全量合并生成今天的全量，有哪些方法？（如果不是高版本的话，没有事务功能，无法开启的话处理）
如果开启事务会很慢，为什么会慢？有哪些更好的方法？
说说事务的缺陷？
  其实主要考察的是对拉链表的理解
2. hivesql优化：
  * 哪些会对I/o消耗？
  * 哪些会对内存消耗？
  * 哪些会对cpu消耗？
3. 数据倾斜是怎么造成的？有哪些优化方式？

二. 网易（数据仓库工程师）：

* mapreduce的过程：
* 数据仓库是 如何搭建的？
* hivesql优化：
* mapjoin的原理是什么？
* 排序 order by,sort by 
* 仓库模型搭建

三. 阿里文学(数据仓库工程师)

* 应用层有多少维度？
  时间，事件，国家，语言，站点，渠道（一级渠道，二级渠道，三级渠道）等维度
  如果将这些维度怎么放在同一个表中进行支持任意的组合？在秒级别计算出来提供业务以及前端使用。（参考麒麟的cube多维度预处理的思想）
* 假如说想做一个全局排序的话，而且数据量特别大怎么办？排序肯定是放在一台机器上计算,但是这一台计算无法支持或者说计算超级慢，怎么办？
* 排序算法是有哪些？主要说说归并排序，因为在mapreduce中使用
* hivesql的排序的原理？
* 目前网站每天的pv,uv,订单多少？

四。百度：（数据仓库工程师）

* 介绍下公司数据仓库是如何搭建的？ods,mds,sds,是如何搭建的？有哪些功能？每层的作用是？
* 多维分析，混合模型（星星模型和雪花模型混合，星型为主）
* 是如何搭建的表的？  a.确定业务 b.确定度量 c.确定粒度  d.确定维度 e.建立维度表
* 三范式是？雪花模型和星型模型？
* hivesql优化：数据倾斜
* replication join和hash join介绍。还有打乱到多台reduce中的参数
* 排序的几种区别？（sort by,order by ,cluster by,distribute by区别以及定义）
* 几种join方式？

null在数据底层是以什么形式进行存储的？

--> null在hive中是"\N"
判断空时要根据实际的存储来进行判断。在开发过程中如果需要对空进行判断，一定得知道存储的是哪种数据。
有个处理空的小技巧，Hive给出一种并非完美的解决方法——自定义底层用什么字符来表示NULL：
使用：ALTER TABLE b SET SERDEPROPERTIES ('serialization.null.format'='');
这句话的意思是让null和''等价，也就是让null不显示，因为null对开发来说不好操作，可能不同地方代表意义不同，
而且转码可能也会有问题，所有用''代替
null转化为空字符串，还可以节省空间

* 不同数据类型对空值的存储规则
int与string类型数据存储，null默认存储为 \N；
string类型的数据如果为""，存储则是""；
另外往int类型的字段插入数据“”时，结果还是\N。
* 不同数据类型，空值的查询
对于int可以使用is null来判断空；
而对于string类型，条件is null 查出来的是\N的数据；而条件 =’’，查询出来的是""的数据。

* 本地数据加载，这个问题最简单，当然没有准备纯手写的话，不一定完全写对啊

-->LOAD DATA LOCAL  INPATH 'test.txt' overwrite into ods_log_pageview partition (dt = ‘etl_date’)

* 情景模拟的考验沟通能力？
* 行专列
* mysql的优化