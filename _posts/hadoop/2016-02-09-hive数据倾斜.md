---
layout: article
title:  "hive数据倾斜那点事"
categories: hadoop
toc: true
image:
    teaser: /teaser/平衡概念的不平衡状态-43938397.jpg
---

> 本文主要介绍数据倾斜是如何产生的，以及数据倾斜应该如何优化。


### 前言
&emsp;&emsp;hive数据倾斜是对于数据hive sql开发人员来说是非常头疼的事情，本来hive使用的mapreduce计算引擎延迟比较高，如果遇到数据倾斜的话，那就更糟糕了。即使将引擎切换到spark进行计算。效果也不是很好。

## 什么是数据倾斜？
由于大数据使用的是分布式计算处理，数据分散的不均匀的话，会将大量的数据放到一台或者几台机器中进行处理。这些数据的计算速度远远低于平均计算速度，导致整个计算过程过慢
![数据倾斜](/images/hadoop/YARN/数据倾斜1.jpg)

## 现象
数据倾斜主要表现在、ruduce阶段卡在99.99%，一直99.99%不能结束
* 有一个或者几个reduce卡住
* 各种container报错OOM
* 读写的数据量极大，至少远远超过其它正常的reduce
> 经验：Hive的数据倾斜，一般都发生在Sql中Group和On上，而且和数据逻辑绑定比较深。

## 产生原因
> 他们在做数据运算的时候会设计到，countdistinct、group by、join等操作，这些都会触发Shuffle动作，一旦触发，所有相同key的值就会拉到一个或几个节点上，就容易发生单点问题.基本上发送shuffle过程中。

* 举例：
比如就说订单场景吧，我们在某一天在北京和上海两个城市多了强力的推广，结果可能是这两个城市的订单量增长了10000%，其余城市的数据量不变。然后我们要统计不同城市的订单情况，这样，一做group操作，可能直接就数据倾斜了。

## 解决办法：
* mapjoin方式
* count distinct的操作，先转成group，再count
* 万能膏药：hive.groupby.skewindata=true （设置负载均衡）
* left semi jioin的使用
* 设置map端输出、中间结果压缩。（不完全是解决数据倾斜的问题，但是减少了IO读写和网络传输，能提高很多效率）



* 解压

{% highlight bash %}
{% raw %}
unzip kafka-manager-1.3.4.zip
{% endraw %}
{% endhighlight %}
