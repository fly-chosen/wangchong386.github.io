---
layout: article
title:  "流式计算flume-kafka-sparkstreaming案例(三)"
categories: spark
toc: true
image:
    teaser: /teaser/spark.png
---

> 这篇内容主要介绍流式计算之sparkstreaming调优



### 前言
&emsp;&emsp;sparkstreaming+kafka这种流式处理方式，在数据量比较小的情况下是可以选择默认配置进行运行处理的，但是当数据量比较大的情况下，就需要调整设置一些参数使其性能达到最优。本篇这要是根据公司生产环境的情况进行配置的。没有一个标准的配置，是需要不断的尝试才可能达到性能最优。(所以好的配置是需要慢慢配置的)
## sparkstreaming任务的划分
* kafka中一个topic对应一张hive里的表
* kafka topic里面的partition设置为6个
* streaming job即kafka的消费者，每次同时消费10个topic
## 设置合理的批处理时间(batchDuration)
在初始化streamingcontext的时候会传进一个参数，用于设置Spark Streaming批处理的时间间隔。Spark会每隔batchDuration时间去提交一次Job，如果你的Job处理的时间超过了batchDuration的设置，那么会导致后面的作业无法按时提交，随着时间的推移，越来越多的作业被拖延，最后导致整个Streaming作业被阻塞，这就间接地导致无法实时处理数据。

